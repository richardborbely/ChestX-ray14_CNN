{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPanprt3Tglz"
   },
   "outputs": [],
   "source": [
    "import os, math, random, glob, zipfile, pickle\n",
    "import pandas as fp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy as sp\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, AveragePooling2D, BatchNormalization, ZeroPadding2D, Activation\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xS5Irx4I13IC"
   },
   "outputs": [],
   "source": [
    "# Copy the dataset from Google Drive to Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# dataset = zipfile.ZipFile(\"/content/drive/My Drive/Dissertation/Imgs/Slim/dataset_slim.zip\", 'r')\n",
    "# dataset.extractall(\"/content/Imgs/\")\n",
    "# dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQJQE4S_FRNV"
   },
   "outputs": [],
   "source": [
    "# Colab runtime environment #\n",
    "# BASE_DIR = \"../content/drive/My Drive/Dissertation\"\n",
    "# _data = fp.read_csv(\"../content/drive/My Drive/Dissertation/data_slim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4peNnN2U13IE"
   },
   "outputs": [],
   "source": [
    "# Local runtime environment #\n",
    "BASE_DIR = \".\"\n",
    "_data = fp.read_csv(\"./data_slim.csv\") # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Disinclude classes\n",
    "# removableFindings = [\"Hernia\", \"Pneumonia\", \"Edema\", \"Fibrosis\", \"Emphysema\", \"|\", \"Cardiomegaly\", \"Pleural_Thickening\", \"Consolidation\", \"Mass\", \"Pneumothorax\", \"Nodule\", \"Effusion\", \"Atelectasis\"]\n",
    "# # Collect\n",
    "# removable = []\n",
    "# for index, row in _data.iterrows():\n",
    "#     for f in removableFindings:\n",
    "#         if f in row[\"Finding Labels\"]:\n",
    "#             removable.append(index) \n",
    "# # Drop\n",
    "# _data = _data.drop(removable)\n",
    "# print(\"Removed : \" + str(len(removable)))\n",
    "# # Update classes\n",
    "# _classes = np.unique([x.split('|')[0] for x in _data[\"Finding Labels\"]]).tolist() # Get all UNIQUE classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgUASxsc16Ys"
   },
   "outputs": [],
   "source": [
    "# # PRE-PROCESS DATASET #\n",
    "# # Only to be done once, then data_slim.csv to be used as input\n",
    "\n",
    "# _data = fp.read_csv(\"./data.csv\") # File containing all datapoints\n",
    "# _classes = np.unique([x.split('|')[0] for x in _data[\"Finding Labels\"]]).tolist() # Get all UNIQUE classes\n",
    "\n",
    "\n",
    "# # Remove unwanted columns\n",
    "# _data = _data.drop(columns=[\"Follow-up #\", \"Patient ID\", \"Patient Age\", \"Patient Gender\", \n",
    "#                           \"View Position\", \"OriginalImageWidth\", \"OriginalImageHeight\", \n",
    "#                           \"OriginalImagePixelSpacingX\", \"OriginalImagePixelSpacingY\"])\n",
    "\n",
    "\n",
    "# # Disinclude classes with low instance count\n",
    "# # removableFindings = [\"Hernia\"]\n",
    "# # # Collect\n",
    "# # removable = []\n",
    "# # for index, row in _data.iterrows():\n",
    "# #     for f in removableFindings:\n",
    "# #         if f in row[\"Finding Labels\"]:\n",
    "# #             removable.append(index) \n",
    "# # # Drop\n",
    "# # _data = _data.drop(removable)\n",
    "# # print(\"Removed : \" + str(len(removable)))\n",
    "# # # Update classes\n",
    "# # _classes = np.unique([x.split('|')[0] for x in _data[\"Finding Labels\"]]).tolist() # Get all UNIQUE classes\n",
    "\n",
    "\n",
    "# # Reduce instance count of No Finding\n",
    "# COUNT_MAX = 10000\n",
    "# # Collect all instances\n",
    "# removable = []\n",
    "# for index, row in _data.iterrows():\n",
    "#     if \"No Finding\" in row[\"Finding Labels\"]:\n",
    "#         removable.append(index) \n",
    "\n",
    "#     # Pick COUNT_MAX random instances that stay in the dataset\n",
    "# for i in range(COUNT_MAX):\n",
    "#     removable.remove(random.choice(removable))\n",
    "# # Drop\n",
    "# _data = _data.drop(removable)\n",
    "# print(\"Removed : \" + str(len(removable)))\n",
    "\n",
    "\n",
    "# # Save new data file\n",
    "# _data.to_csv(\"./data_slim.csv\", index=False, mode=\"w\")\n",
    "\n",
    "\n",
    "# # Resize images\n",
    "# for file in _data[\"Image Index\"]:\n",
    "#     src = \"./Imgs/All/\" + file\n",
    "#     dest = \"./Imgs/Slim_Cropped/\"\n",
    "#     # Resize\n",
    "#     img = Image.open(src)\n",
    "#     area = (100, 100, 924, 924)\n",
    "#     cropped_img = img.crop(area)\n",
    "# #     cropped_img.show()\n",
    "#     cropped_img = cropped_img.resize((224, 224), Image.LANCZOS)\n",
    "#     cropped_img.save(dest + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXcxq30XTgl4"
   },
   "outputs": [],
   "source": [
    "# GLOBALS #\n",
    "_classes = np.unique([x.split('|')[0] for x in _data[\"Finding Labels\"]]).tolist() # Get all UNIQUE classes\n",
    "session = None\n",
    "\n",
    "# FUNCTIONS #\n",
    "def SeparateClasses(set):\n",
    "    # Create Classes colums - list of classes\n",
    "    set[\"Classes\"] = set[\"Finding Labels\"].apply(lambda x:x.split(\"|\"))\n",
    "    return set\n",
    "\n",
    "\n",
    "def GetUniqueClassCounts(set):\n",
    "  # Find UNIQUE classes + class ID + counts\n",
    "    labels = set.value_counts().to_dict()\n",
    "    remove = []\n",
    "    for label in labels:\n",
    "        if '|' in label:\n",
    "            classes = label.split('|')\n",
    "            for c in classes:\n",
    "                labels[c] += labels[label]\n",
    "            remove.append(label)\n",
    "        \n",
    "    for r in remove:\n",
    "        labels.pop(r)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def GetClassWeights(set):\n",
    "  # Calculate class weights\n",
    "    unique_class_instances = GetUniqueClassCounts(set[\"Finding Labels\"])\n",
    "    CLASS_WEIGHTS = {}\n",
    "    maxWeight = 0\n",
    "    # Find max - which is going to be the base weight (1)\n",
    "    for c in unique_class_instances:\n",
    "        if unique_class_instances[c] > maxWeight:\n",
    "            maxWeight = unique_class_instances[c]\n",
    "    # Calculate individual weights\n",
    "    for c in unique_class_instances:\n",
    "        weight = round(1 / (unique_class_instances[c] / maxWeight), 2)\n",
    "        CLASS_WEIGHTS[_classes.index(c)] = weight\n",
    "\n",
    "    # for k, v in weights.items():\n",
    "    #   print(_classes[k], \":\", unique_class_instances[_classes[k]], \":\", k, \":\", v)\n",
    "    return CLASS_WEIGHTS\n",
    "\n",
    "# Save figures\n",
    "def SaveFigure(fig, name):\n",
    "    if os.path.isfile(name):\n",
    "        os.remove(name)\n",
    "    fig.savefig(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_\" + name)\n",
    "\n",
    "\n",
    "# Print class counts\n",
    "for c in GetUniqueClassCounts(_data[\"Finding Labels\"]):\n",
    "    print(c + \" : \" + str(_classes.index(c)) + \" : \"+ str(GetUniqueClassCounts(_data[\"Finding Labels\"])[c]))\n",
    "\n",
    "# Create Classes column\n",
    "_data = SeparateClasses(_data)\n",
    "_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW SESSION #\n",
    "\n",
    "session = \"-\"\n",
    "newS = True\n",
    "\n",
    "if not os.path.exists(BASE_DIR + \"/Sessions\"): # Create folder if it doesn't exist\n",
    "    os.makedirs(BASE_DIR + \"/Sessions\")\n",
    "if not os.path.exists(BASE_DIR + \"/Sessions/\" + session): # Create folder if it doesn't exist\n",
    "    os.makedirs(BASE_DIR + \"/Sessions/\" + session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZiD7yTiTgmI"
   },
   "outputs": [],
   "source": [
    "# LOAD A PREVIOUS SESSION #\n",
    "\n",
    "session = \"_Mobile_transfer\" # Specify which session to load\n",
    "newS = False\n",
    "\n",
    "# Load session's dataset\n",
    "train_set = fp.read_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_train.csv\")\n",
    "valid_set = fp.read_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_valid.csv\")\n",
    "test_set = fp.read_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_test.csv\")\n",
    "train_set = SeparateClasses(train_set)\n",
    "valid_set = SeparateClasses(valid_set)\n",
    "test_set = SeparateClasses(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9MpVvhK13IP"
   },
   "outputs": [],
   "source": [
    "# IMAGE GENERATOR + BATCH GENERATORS #\n",
    "\n",
    "if newS: # Split fresh dataset\n",
    "    print(\"New Session: \" + session)\n",
    "    train_set, test_set = train_test_split(_data, test_size=0.2)\n",
    "    train_set, valid_set = train_test_split(train_set, test_size=0.13)\n",
    "else: print(\"Session: \" + session)\n",
    "\n",
    "print(\"Training size: \" + str(train_set.shape[0]))\n",
    "print(\"Valid size: \" + str(valid_set.shape[0]))\n",
    "print(\"Test size: \" + str(test_set.shape[0]))\n",
    "\n",
    "# Define image generator\n",
    "img_generator = ImageDataGenerator( \n",
    "    rescale=1./255.,\n",
    "    rotation_range=10,\n",
    "    zoom_range=[0.85, 1.0],\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Properties\n",
    "BATCH_SIZE = 32\n",
    "IMG_COLOR = 'rgb'\n",
    "IMG_SIZE = (224, 224) #(299, 299)\n",
    "DIR = 'Imgs/Slim_Cropped' # Resized images dir\n",
    "\n",
    "# Define batch generators\n",
    "train_batch = img_generator.flow_from_dataframe(\n",
    "        dataframe=train_set,\n",
    "        directory=DIR,\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=\"Classes\",\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode=IMG_COLOR,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        classes=_classes)\n",
    "valid_batch = img_generator.flow_from_dataframe(\n",
    "        dataframe=valid_set,\n",
    "        directory=DIR,\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=\"Classes\",\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode=IMG_COLOR,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        classes=_classes)\n",
    "test_batch = ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
    "        dataframe=test_set,\n",
    "        directory=DIR,\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=\"Classes\",\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode=IMG_COLOR,\n",
    "        shuffle=False,\n",
    "        batch_size=128,\n",
    "        class_mode='categorical',\n",
    "        classes=_classes)\n",
    "\n",
    "# Evaluate split efficiency - every set should include all classes\n",
    "train_y_unique_count = len(np.unique([x.split('|')[0] for x in train_set[\"Finding Labels\"]]).tolist())\n",
    "valid_y_unique_count = len(np.unique([x.split('|')[0] for x in valid_set[\"Finding Labels\"]]).tolist())\n",
    "test_y_unique_count = len(np.unique([x.split('|')[0] for x in test_set[\"Finding Labels\"]]).tolist())\n",
    "if train_y_unique_count != valid_y_unique_count or train_y_unique_count != test_y_unique_count:\n",
    "    print(\"UNBALANCED SPLIT!\")\n",
    "else: print(\"BALANCED SPLIT!\")\n",
    "\n",
    "# Visualise some of the data and format\n",
    "x = next(train_batch)\n",
    "print(\"Label encoding format: \", x[1][0])\n",
    "train_batch.reset()\n",
    "f, img = plt.subplots(2,4, figsize = (15, 15))\n",
    "plt.subplots_adjust(top=0.5, bottom=0.1, hspace=0.2, wspace=0.2)\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        if IMG_COLOR is \"grayscale\":\n",
    "            img[i, j].imshow(np.repeat(x[0][i * 4 + j], 3, 2))\n",
    "\n",
    "        else:\n",
    "            img[i, j].imshow(x[0][i * 4 + j])\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TzxgOsS13IU"
   },
   "outputs": [],
   "source": [
    "# IMPORT SESSION MODEL # \n",
    "\n",
    "model = load_model(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_model.h5\")\n",
    "model.summary()\n",
    "history = tf.keras.callbacks.History()\n",
    "prev_history = pickle.load(open(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\", \"rb\")) # Load session history\n",
    "EPOCHS = len(prev_history[\"val_accuracy\"]) # Get no. epochs\n",
    "\n",
    "# Show session AUROC if exists\n",
    "if os.path.exists(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_AUROC.png\"):\n",
    "    auroc=mpimg.imread(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_AUROC.png\")\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(auroc)\n",
    "    plt.show()\n",
    "\n",
    "print(EPOCHS)\n",
    "# model.fit(train_batch,\n",
    "#         steps_per_epoch=math.ceil(train_set.shape[0] / BATCH_SIZE), # (num_samples / batch_size)\n",
    "#         epochs=30,\n",
    "#         validation_data=valid_batch,\n",
    "#         validation_steps=math.ceil(valid_set.shape[0] / BATCH_SIZE),\n",
    "#         class_weight=GetClassWeights(train_set),\n",
    "#         callbacks=[history],\n",
    "#         initial_epoch=EPOCHS,\n",
    "#         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4ptIlYHTgmN"
   },
   "outputs": [],
   "source": [
    "# MOBILENET #\n",
    "\n",
    "# Load model from library\n",
    "mbNet = MobileNet(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
    "# Remove last few layers\n",
    "x = GlobalAveragePooling2D()(mbNet.layers[-14].output)\n",
    "# Add final activation layer\n",
    "x = Dense(len(_classes), activation='sigmoid')(x)\n",
    "# Compile model\n",
    "model = Model(inputs=mbNet.input, outputs=x)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='val_mae', mode='max', min_delta=0.01, patience=5, verbose=1)\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "model.fit(train_batch,\n",
    "        steps_per_epoch=math.ceil(train_set.shape[0] / BATCH_SIZE), #(num_samples / batch_size)\n",
    "        epochs=20,\n",
    "        validation_data=valid_batch,\n",
    "        validation_steps=math.ceil(valid_set.shape[0] / BATCH_SIZE),\n",
    "        class_weight=GetClassWeights(train_set),\n",
    "        callbacks=[history],\n",
    "        initial_epoch=0,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RDzZB2woTgmU"
   },
   "outputs": [],
   "source": [
    "# VGG #\n",
    "# Load model from library\n",
    "vgg = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\",\n",
    "                                input_tensor=None, input_shape=(224, 224, 3), pooling=\"avg\")\n",
    "\n",
    "# Add final activation layer\n",
    "x = Dense(len(_classes), activation='softmax')(vgg.output)\n",
    "# Compile model\n",
    "model = Model(inputs=vgg.input, outputs=x)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "earlyStop = callbacks.EarlyStopping(monitor='loss', mode='max', min_delta=0.01, patience=5, verbose=1)\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "model.fit(train_batch,\n",
    "        steps_per_epoch=math.ceil(train_set.shape[0] / BATCH_SIZE), #(num_samples / batch_size)\n",
    "        epochs=30,\n",
    "        validation_data=valid_batch,\n",
    "        validation_steps=math.ceil(valid_set.shape[0] / BATCH_SIZE),\n",
    "        class_weight=GetClassWeights(train_set),\n",
    "        callbacks=[history],\n",
    "        initial_epoch=0,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "q4lsIPwtTgmZ"
   },
   "outputs": [],
   "source": [
    "# RESNET #\n",
    "# Load model from library\n",
    "resnet = keras.applications.resnet.ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                    input_tensor=None, input_shape=(224, 224, 3), pooling=\"avg\")\n",
    "\n",
    "# Add final activation layer\n",
    "x = Dense(len(_classes), activation='sigmoid')(resnet.output)\n",
    "# Compile model\n",
    "model = Model(inputs= resnet.input, outputs=x)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
    "model.summary()\n",
    "\n",
    "earlyStop = callbacks.EarlyStopping(monitor='loss', mode='max', min_delta=0.01, patience=5, verbose=1)\n",
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "model.fit(train_batch,\n",
    "        steps_per_epoch=math.ceil(train_set.shape[0] / BATCH_SIZE), #(num_samples / batch_size)\n",
    "        epochs=30,\n",
    "        validation_data=valid_batch,\n",
    "        validation_steps=math.ceil(valid_set.shape[0] / BATCH_SIZE),\n",
    "        class_weight=GetClassWeights(train_set),\n",
    "        callbacks=[history],\n",
    "        initial_epoch=0,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Conv layer outputs #\n",
    "\n",
    "test_batch.reset()\n",
    "x_test, y_test = next(test_batch) # Get a batch of test data\n",
    "conv_layers = [x for x in model.layers if type(x) == type(Conv2D(2, (1,1)))] # Put all conv layers in a list\n",
    "num_conv_layers = len([x for x in model.layers if type(x) == type(Conv2D(2, (1,1)))]) # count\n",
    "\n",
    "f, img = plt.subplots(num_conv_layers, 5, figsize = (15, 30)) # Define figure\n",
    "\n",
    "for imageCount in range(10): # amount of input images - how many activation maps to generate\n",
    "    for j in range(num_conv_layers): # for every convolutional layer\n",
    "        # Take the layers from the model\n",
    "        initial_input_layer = model.input\n",
    "        last_conv_layer = conv_layers[j].output\n",
    "\n",
    "        cam_model = Model(inputs=initial_input_layer, outputs=(last_conv_layer))\n",
    "        features = cam_model.predict(x_test) # Predict batch using the cam model\n",
    "\n",
    "        image_features = features[imageCount,:,:,:] # take input first image\n",
    "\n",
    "        plt.subplots_adjust(top=1.0, bottom=0.0, hspace=0.1, wspace=0.1)\n",
    "\n",
    "        for i in range(5):\n",
    "            featureIMG = image_features[:,:,i]\n",
    "            img[j, i].imshow(featureIMG)\n",
    "            img[j, i].set_yticks([])\n",
    "            img[j, i].set_xticks([])\n",
    "#     f.show()\n",
    "    SaveFigure(f, \"activation_maps#\" + str(imageCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZUGBHn813Ii"
   },
   "outputs": [],
   "source": [
    "# CLASS ACTIVATION MAP #\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# Get model input layer\n",
    "initial_input_layer = model.input\n",
    "# Get the last convolutional layer\n",
    "def get_LastConvLayer():\n",
    "    return [x for x in model.layers if type(x) == type(Conv2D(2, (1,1)))][-1]\n",
    "last_conv_layer = get_LastConvLayer().output\n",
    "# Get the classification layer\n",
    "classification_layer = model.layers[-1].output\n",
    "classification_layer_weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "# Class activation map model\n",
    "cam_model = Model(inputs=initial_input_layer, outputs=(last_conv_layer, classification_layer))\n",
    "\n",
    "next(test_batch)\n",
    "x_test, y_test = next(test_batch) # Get a batch of test data\n",
    "features, results = cam_model.predict(x_test) # Predict batch using the cam model\n",
    "print(\"Last conv layer feature shape: \", features.shape)\n",
    "\n",
    "for i in range(100):\n",
    "    image_features = features[i,:,:,:] # Image features recognised by the convolutional layer\n",
    "    \n",
    "    height_multiplier = x_test.shape[1]/image_features.shape[0] # full size / feature size\n",
    "    width_multiplier = x_test.shape[2]/image_features.shape[1]\n",
    "\n",
    "    # Apply bilinear upscaling to match the size of the input \n",
    "    cam_features = sp.ndimage.zoom(image_features, (height_multiplier, width_multiplier, 1), order=2)\n",
    "\n",
    "    pred = np.argmax(results[i]) # Get a prediction for i\n",
    "    cam_weights = classification_layer_weights[:, pred] # Get the weights from the classification layer for i\n",
    "    cam_output = np.dot(cam_features, cam_weights) # Compute the dot product of the feature maps and the weights\n",
    "    \n",
    "    # Show / save images\n",
    "#     label = \"Predicted = \" + _classes[pred] + \", % = \" + str(results[i][pred])\n",
    "    label = _classes[pred]\n",
    "    fig_cam, img = plt.subplots(figsize = (6, 6))\n",
    "#     fig_cam = plt.figure(figsize = (6, 6))\n",
    "    plt.xlabel(label)\n",
    "    img.set_yticks([])\n",
    "    img.set_xticks([])\n",
    "    plt.imshow(x_test[i],  alpha=0.9, extent=(0, 224, 0, 224))\n",
    "    plt.imshow(cam_output, cmap=\"jet\", alpha=0.25, extent=(0, 224, 0, 224))\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    SaveFigure(fig_cam, \"cam#\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZNxdMIXTgml"
   },
   "outputs": [],
   "source": [
    "# EVALUATION #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lml9UO3Tgms"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_batch.reset()\n",
    "print(\"Test evaluation scores: \", model.evaluate(test_batch, verbose=1))\n",
    "\n",
    "\n",
    "# Get ground truth labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_test = mlb.fit_transform(test_set[\"Classes\"])\n",
    "\n",
    "\n",
    "# Get predictions\n",
    "test_batch.reset()\n",
    "y_pred = model.predict(test_batch,\n",
    "        steps=math.ceil(test_set.shape[0] / 128),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYKr_WCnTgm7"
   },
   "outputs": [],
   "source": [
    "# Calculate AUROC\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUROC score: \", roc_auc)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fig_auroc, fig = plt.subplots(1,1, figsize = (10, 10))\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=2, linestyle=\"dashed\")\n",
    "for i in range(len(_classes)):\n",
    "    fpr, tpr, _ = roc_curve(y_test[:,i], y_pred[:,i]) # [:,i] column value\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig.plot(fpr, tpr, label = _classes[i] + \"-AUC: \" + str(round(roc_auc, 3)))\n",
    "fig.legend()\n",
    "fig.set_xlabel(\"False Positive Rate\")\n",
    "fig.set_ylabel(\"True Positive Rate\")\n",
    "fig.set_title(\"ROC Curve per Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBVmvvrCTgmn"
   },
   "outputs": [],
   "source": [
    "# Append to previous history dictionary, IF one exists\n",
    "hist = history.history\n",
    "if session is not None and os.path.exists(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\"):\n",
    "    prev_history = pickle.load(open(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\", \"rb\"))\n",
    "    ep = len(hist[\"val_accuracy\"]) # Get no. epochs\n",
    "    for i in range(ep): # for every epoch\n",
    "        for metric in prev_history.keys(): # for every metric\n",
    "            prev_history[metric].append(hist[metric][i]) # append the epoch's metrics to the prev. hist.\n",
    "    hist = prev_history\n",
    "\n",
    "# Plot accuracy\n",
    "fig_accuracy = plt.figure(figsize = (8, 5))\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist['val_accuracy'])\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
    "plt.show()\n",
    "# Plot loss\n",
    "fig_loss = plt.figure(figsize = (8, 5))\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.title(\"Training Loss \")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Loss\",\"Validation Loss\"])\n",
    "plt.show()\n",
    "# Plot MAE\n",
    "fig_mae = plt.figure(figsize = (8, 5))\n",
    "plt.plot(hist['mae'])\n",
    "plt.plot(hist['val_mae'])\n",
    "plt.title(\"Training MAE\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"MAE\",\"Validation MAE\"])\n",
    "plt.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h81ihZnyUsCa"
   },
   "outputs": [],
   "source": [
    "# SAVE SESSION #\n",
    "\n",
    "# Save confusion matrix to file\n",
    "conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "with open(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_confusionM.txt\", \"w\") as f:\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "    f.close()\n",
    "\n",
    "# Save dataset\n",
    "train_set = train_set.drop(columns=[\"Classes\"]) # Drop bad columns - comma separation not compatible with import split\n",
    "valid_set = valid_set.drop(columns=[\"Classes\"])\n",
    "test_set = test_set.drop(columns=[\"Classes\"])\n",
    "train_set.to_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_train.csv\", index=False, mode=\"w\")\n",
    "valid_set.to_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_valid.csv\", index=False, mode=\"w\")\n",
    "test_set.to_csv(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_test.csv\", index=False, mode=\"w\")\n",
    "\n",
    "# Append to previous history dictionary, IF one exists\n",
    "# NOTE: file exist check will fail if the session is being renamed, comment out next line and let hist variable come from the above cell\n",
    "hist = history.history\n",
    "if os.path.exists(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\"):\n",
    "    prev_history = pickle.load(open(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\", \"rb\"))\n",
    "    ep = len(hist[\"val_accuracy\"]) # Get no. epochs\n",
    "    for i in range(ep): # for every epoch\n",
    "        for metric in prev_history.keys(): # for every metric\n",
    "            prev_history[metric].append(hist[metric][i]) # append the epoch's metrics to the prev. hist.\n",
    "    hist = prev_history\n",
    "# Save training history obj. as binary file\n",
    "with open(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \".history\", \"wb\") as f:\n",
    "    pickle.dump(hist, f)\n",
    "    f.close()\n",
    "\n",
    "# Save model - includes structure, weights, optimizer weights..\n",
    "model.save(BASE_DIR + \"/Sessions/\" + session + \"/m_\" + session + \"_model.h5\", overwrite=True) # Model\n",
    "\n",
    "SaveFigure(fig_auroc, \"AUROC\")\n",
    "SaveFigure(fig_accuracy, \"accuracy_history\")\n",
    "SaveFigure(fig_loss, \"loss_history\")\n",
    "SaveFigure(fig_mae, \"mae_history\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ChestXrayNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
